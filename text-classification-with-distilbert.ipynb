{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-22T14:02:47.589323Z","iopub.execute_input":"2023-07-22T14:02:47.590541Z","iopub.status.idle":"2023-07-22T14:02:47.604374Z","shell.execute_reply.started":"2023-07-22T14:02:47.590496Z","shell.execute_reply":"2023-07-22T14:02:47.603197Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/bbc-fulltext-and-category/bbc-text.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(os.path.join(dirname, filename))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:02:48.727340Z","iopub.execute_input":"2023-07-22T14:02:48.727788Z","iopub.status.idle":"2023-07-22T14:02:48.883638Z","shell.execute_reply.started":"2023-07-22T14:02:48.727747Z","shell.execute_reply":"2023-07-22T14:02:48.882710Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        category                                               text\n0           tech  tv future in the hands of viewers with home th...\n1       business  worldcom boss  left books alone  former worldc...\n2          sport  tigers wary of farrell  gamble  leicester say ...\n3          sport  yeading face newcastle in fa cup premiership s...\n4  entertainment  ocean s twelve raids box office ocean s twelve...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tech</td>\n      <td>tv future in the hands of viewers with home th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>business</td>\n      <td>worldcom boss  left books alone  former worldc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sport</td>\n      <td>tigers wary of farrell  gamble  leicester say ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sport</td>\n      <td>yeading face newcastle in fa cup premiership s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entertainment</td>\n      <td>ocean s twelve raids box office ocean s twelve...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:02:52.194406Z","iopub.execute_input":"2023-07-22T14:02:52.194770Z","iopub.status.idle":"2023-07-22T14:03:05.142074Z","shell.execute_reply.started":"2023-07-22T14:02:52.194739Z","shell.execute_reply":"2023-07-22T14:03:05.140842Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:03:05.144480Z","iopub.execute_input":"2023-07-22T14:03:05.144948Z","iopub.status.idle":"2023-07-22T14:03:05.162866Z","shell.execute_reply.started":"2023-07-22T14:03:05.144908Z","shell.execute_reply":"2023-07-22T14:03:05.161483Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"sport            511\nbusiness         510\npolitics         417\ntech             401\nentertainment    386\nName: category, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Import required libraries\nimport pandas as pd\nimport tensorflow as tf\nfrom transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n\n# Step 1: Doing the train/test split\nX = list(df['text'])\ndf['encoded_text'] = df['category'].astype('category').cat.codes\ny = list(df.encoded_text)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n\n# Step 2: Tokenizing the train and test data\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\ntrain_encodings = tokenizer(X_train, truncation=True, padding=True)\ntest_encodings = tokenizer(X_test, truncation=True, padding=True)\n\n# Step 3: Converting the data to tensors\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))\n\n# Step 4: Setting up the training arguments for the model\ntraining_args = TFTrainingArguments(\n    output_dir='./results',          # Output directory\n    num_train_epochs=2,              # Total number of training epochs\n    per_device_train_batch_size=8,   # Batch size per device during training\n    per_device_eval_batch_size=16,   # Batch size for evaluation\n    warmup_steps=500,                # Number of warmup steps for the learning rate scheduler\n    weight_decay=0.001,              # Strength of weight decay\n    logging_dir='./logs',            # Directory for storing logs\n    logging_steps=10,\n    eval_steps=100,                 # Number of steps to evaluate the model at\n)\n\n# Step 5: Creating the model for sequence classification\nwith training_args.strategy.scope():\n    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n\n# Step 6: Setting up the trainer\ntrainer = TFTrainer(\n    model=model,                  # The instantiated Transformers model to be trained\n    args=training_args,           # Training arguments, defined above\n    train_dataset=train_dataset,  # Training dataset\n    eval_dataset=test_dataset     # Evaluation dataset\n)\n\n# Step 7: Training the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T14:03:08.081930Z","iopub.execute_input":"2023-07-22T14:03:08.082311Z","iopub.status.idle":"2023-07-22T14:07:08.016202Z","shell.execute_reply.started":"2023-07-22T14:03:08.082277Z","shell.execute_reply":"2023-07-22T14:07:08.014939Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9186ac6cfd64c16a246f37c12e1bce4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab7d25a55d9d4a73af9293fa021bfd06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9846c095b43426ab5726ccbd860a16d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64168af7f4fb47da885b73ed0e4f1b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da1ade8f76b4d9f95414a67de5f64fb"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/trainer_tf.py:118: FutureWarning: The class `TFTrainer` is deprecated and will be removed in version 5 of Transformers. We recommend using native Keras instead, by calling methods like `fit()` and `predict()` directly on the model object. Detailed examples of the Keras style can be found in our examples at https://github.com/huggingface/transformers/tree/main/examples/tensorflow\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230722_140400-0enrce3n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dsingh1-tekshapers/huggingface/runs/0enrce3n' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/dsingh1-tekshapers/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dsingh1-tekshapers/huggingface' target=\"_blank\">https://wandb.ai/dsingh1-tekshapers/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dsingh1-tekshapers/huggingface/runs/0enrce3n' target=\"_blank\">https://wandb.ai/dsingh1-tekshapers/huggingface/runs/0enrce3n</a>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Step 8: Evaluating the model on the test dataset\ntrainer.evaluate(test_dataset)\n\n# Step 9: Making predictions on the test dataset\noutput = trainer.predict(test_dataset)[1]\n\n# Step 10: Calculating the confusion matrix\ncm = confusion_matrix(y_test, output)\n\n# Step 11: Calculating the accuracy score\naccuracy = accuracy_score(y_test, output)\n\n# Print the confusion matrix and accuracy score\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:52:06.949135Z","iopub.execute_input":"2023-07-22T13:52:06.949608Z","iopub.status.idle":"2023-07-22T14:00:13.332096Z","shell.execute_reply.started":"2023-07-22T13:52:06.949571Z","shell.execute_reply":"2023-07-22T14:00:13.330842Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 97   0   0   0   0]\n [  0  81   0   0   0]\n [  0   0  75   0   0]\n [  0   0   0 112   0]\n [  0   0   0   0  80]]\nAccuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}